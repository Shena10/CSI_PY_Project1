{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPY26yHVTNgsrzINs7KS9aQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shena10/CSI_PY_Project1/blob/main/Copy_of_Homework1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAAqULjiqAbZ",
        "outputId": "0fca76ef-a3d4-47f2-fdd9-d772834bb2ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   target  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "sepal length (cm)    0\n",
            "sepal width (cm)     0\n",
            "petal length (cm)    0\n",
            "petal width (cm)     0\n",
            "target               0\n",
            "dtype: int64\n",
            "Training set size: 105\n",
            "Testing set size: 45\n",
            "Decision Tree Accuracy: 1.0\n",
            "Decision Tree Precision: 1.0\n",
            "Decision Tree Confusion Matrix:\n",
            " [[19  0  0]\n",
            " [ 0 13  0]\n",
            " [ 0  0 13]]\n",
            "Perceptron Accuracy: 0.8222222222222222\n",
            "Perceptron Precision: 0.873015873015873\n",
            "Perceptron Confusion Matrix:\n",
            " [[19  0  0]\n",
            " [ 0  5  8]\n",
            " [ 0  0 13]]\n",
            "Perceptron (from scratch) Accuracy: 0.28888888888888886\n",
            "Decision Tree (from scratch) Accuracy: 0.9555555555555556\n",
            "Decision Tree (from scratch) Accuracy: 0.9555555555555556\n"
          ]
        }
      ],
      "source": [
        "# @title Default title text\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Convert the dataset to a DataFrame for easier exploration\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets (70% training, 30% testing)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"Training set size:\", len(X_train))\n",
        "print(\"Testing set size:\", len(X_test))\n",
        "\n",
        "# Import Decision Tree and Perceptron classifiers\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "# Initialize the models\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "perceptron_classifier = Perceptron()\n",
        "\n",
        "# Train the classifiers\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "perceptron_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "y_pred_perceptron = perceptron_classifier.predict(X_test)\n",
        "\n",
        "# Import metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
        "\n",
        "# Decision Tree evaluation\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "precision_dt = precision_score(y_test, y_pred_dt, average='macro')\n",
        "confusion_dt = confusion_matrix(y_test, y_pred_dt)\n",
        "\n",
        "print(\"Decision Tree Accuracy:\", accuracy_dt)\n",
        "print(\"Decision Tree Precision:\", precision_dt)\n",
        "print(\"Decision Tree Confusion Matrix:\\n\", confusion_dt)\n",
        "\n",
        "# Perceptron evaluation\n",
        "accuracy_perceptron = accuracy_score(y_test, y_pred_perceptron)\n",
        "precision_perceptron = precision_score(y_test, y_pred_perceptron, average='macro')\n",
        "confusion_perceptron = confusion_matrix(y_test, y_pred_perceptron)\n",
        "\n",
        "print(\"Perceptron Accuracy:\", accuracy_perceptron)\n",
        "print(\"Perceptron Precision:\", precision_perceptron)\n",
        "print(\"Perceptron Confusion Matrix:\\n\", confusion_perceptron)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate Gini impurity\n",
        "def gini_impurity(labels):\n",
        "    _, counts = np.unique(labels, return_counts=True)\n",
        "    probabilities = counts / len(labels)\n",
        "    return 1 - np.sum(probabilities ** 2)\n",
        "\n",
        "# Function to split dataset\n",
        "def split_dataset(X, y, feature_index, threshold):\n",
        "    left = np.where(X[:, feature_index] <= threshold)\n",
        "    right = np.where(X[:, feature_index] > threshold)\n",
        "    return X[left], X[right], y[left], y[right]\n",
        "\n",
        "# Function to find the best split\n",
        "def best_split(X, y):\n",
        "    best_gini = float('inf')\n",
        "    for feature_index in range(X.shape[1]):\n",
        "        thresholds = np.unique(X[:, feature_index])\n",
        "        for threshold in thresholds:\n",
        "            X_left, X_right, y_left, y_right = split_dataset(X, y, feature_index, threshold)\n",
        "            gini = (len(y_left) / len(y)) * gini_impurity(y_left) + (len(y_right) / len(y)) * gini_impurity(y_right)\n",
        "            if gini < best_gini:\n",
        "                best_gini, best_feature, best_threshold = gini, feature_index, threshold\n",
        "    return best_feature, best_threshold\n",
        "\n",
        "# A very basic recursive tree algorithm (no pruning)\n",
        "def decision_tree(X, y, depth=0, max_depth=3):\n",
        "    if len(np.unique(y)) == 1 or depth == max_depth:\n",
        "        return np.argmax(np.bincount(y))\n",
        "    feature_index, threshold = best_split(X, y)\n",
        "    X_left, X_right, y_left, y_right = split_dataset(X, y, feature_index, threshold)\n",
        "    left_subtree = decision_tree(X_left, y_left, depth + 1, max_depth)\n",
        "    right_subtree = decision_tree(X_right, y_right, depth + 1, max_depth)\n",
        "    return {'feature_index': feature_index, 'threshold': threshold, 'left': left_subtree, 'right': right_subtree}\n",
        "\n",
        "# Example usage (for small datasets):\n",
        "tree = decision_tree(X_train.values, y_train.values)\n",
        "\n",
        "class PerceptronScratch:\n",
        "    def __init__(self, lr=0.01, n_iters=1000):\n",
        "        self.lr = lr\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "                y_predicted = self._activation_function(linear_output)\n",
        "\n",
        "                update = self.lr * (y[idx] - y_predicted)\n",
        "                self.weights += update * x_i\n",
        "                self.bias += update\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        return self._activation_function(linear_output)\n",
        "\n",
        "    def _activation_function(self, x):\n",
        "        return np.where(x >= 0, 1, 0)\n",
        "\n",
        "# Initialize and train\n",
        "perceptron_scratch = PerceptronScratch()\n",
        "perceptron_scratch.fit(X_train.values, y_train.values)\n",
        "y_pred_scratch = perceptron_scratch.predict(X_test.values)\n",
        "\n",
        "class PerceptronScratch:\n",
        "    def __init__(self, lr=0.01, n_iters=1000):\n",
        "        self.lr = lr\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "                y_predicted = self._activation_function(linear_output)\n",
        "\n",
        "                update = self.lr * (y[idx] - y_predicted)\n",
        "                self.weights += update * x_i\n",
        "                self.bias += update\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        return self._activation_function(linear_output)\n",
        "\n",
        "    def _activation_function(self, x):\n",
        "        return np.where(x >= 0, 1, 0)\n",
        "\n",
        "# Initialize and train\n",
        "perceptron_scratch = PerceptronScratch()\n",
        "perceptron_scratch.fit(X_train.values, y_train.values)\n",
        "y_pred_scratch = perceptron_scratch.predict(X_test.values)\n",
        "\n",
        "# Evaluate the Decision Tree and Perceptron implemented from scratch\n",
        "accuracy_scratch = accuracy_score(y_test, y_pred_scratch)\n",
        "print(\"Perceptron (from scratch) Accuracy:\", accuracy_scratch)\n",
        "\n",
        "def predict_tree(tree, X):\n",
        "    if isinstance(tree, dict):\n",
        "        feature_index = tree['feature_index']\n",
        "        threshold = tree['threshold']\n",
        "        if X[feature_index] <= threshold:\n",
        "            return predict_tree(tree['left'], X)\n",
        "        else:\n",
        "            return predict_tree(tree['right'], X)\n",
        "    else:\n",
        "        return tree\n",
        "# Predict on the test set using the decision tree from scratch\n",
        "y_pred_tree = [predict_tree(tree, x) for x in X_test.values]\n",
        "\n",
        "# Evaluate the Decision Tree implemented from scratch\n",
        "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
        "print(\"Decision Tree (from scratch) Accuracy:\", accuracy_tree)\n",
        "\n",
        "# A very basic recursive tree algorithm (no pruning)\n",
        "def decision_tree(X, y, depth=0, max_depth=3):\n",
        "    if len(np.unique(y)) == 1 or depth == max_depth:\n",
        "        return np.argmax(np.bincount(y))\n",
        "    feature_index, threshold = best_split(X, y)\n",
        "    X_left, X_right, y_left, y_right = split_dataset(X, y, feature_index, threshold)\n",
        "    left_subtree = decision_tree(X_left, y_left, depth + 1, max_depth)\n",
        "    right_subtree = decision_tree(X_right, y_right, depth + 1, max_depth)\n",
        "    return {'feature_index': feature_index, 'threshold': threshold, 'left': left_subtree, 'right': right_subtree}\n",
        "\n",
        "# Example usage (for small datasets):\n",
        "tree = decision_tree(X_train.values, y_train.values)\n",
        "\n",
        "# Prediction function for Decision Tree\n",
        "def predict_tree(tree, X):\n",
        "    if isinstance(tree, dict):\n",
        "        feature_index = tree['feature_index']\n",
        "        threshold = tree['threshold']\n",
        "        if X[feature_index] <= threshold:\n",
        "            return predict_tree(tree['left'], X)\n",
        "        else:\n",
        "            return predict_tree(tree['right'], X)\n",
        "    else:\n",
        "        return tree\n",
        "\n",
        "# Predict on the test set using the decision tree from scratch\n",
        "y_pred_tree = [predict_tree(tree, x) for x in X_test.values]\n",
        "\n",
        "# Evaluate the Decision Tree implemented from scratch\n",
        "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
        "print(\"Decision Tree (from scratch) Accuracy:\", accuracy_tree)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}